{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4dc401b",
   "metadata": {},
   "source": [
    "Word Embedding chapter 2.1 assignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36a88fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters in the file: 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g\n"
     ]
    }
   ],
   "source": [
    "with open('corpus/the-verdict.txt', 'r', encoding='utf-8') as file:\n",
    "    raw_text = file.read()\n",
    "print(\"Total number of characters in the file:\", len(raw_text))\n",
    "print(raw_text[:100])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10513aa4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf43e497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello,', ' ', 'world!', ' ', 'a;lkjf', ' ', 'i', ' ', 'know', ' ', 'htat', ' ', 'if', ' ', 'happens']\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "text='hello, world! a;lkjf i know htat if happens'\n",
    "result=re.split(r'(\\s)',text)\n",
    "print(result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79e0957c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', ',', '', ' ', 'world!', ' ', 'a', ';', 'lkjf', ' ', 'i', ' ', 'know', ' ', 'htat', ' ', 'if', ' ', 'happens']\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "text='hello, world! a;lkjf i know htat if happens'\n",
    "result2=re.split(r'([\\s,;])',text)\n",
    "print(result2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ef9ce03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', ' ', 'HAD', ' ', 'always', ' ', 'thought', ' ', 'Jack', ' ', 'Gisburn', ' ', 'rather', ' ', 'a', ' ', 'cheap', ' ', 'genius', '-', '-', 'though', ' ', 'a', ' ', 'good', ' ', 'fellow', ' ', 'enough', '-', '-', 'so', ' ', 'it', ' ', 'was', ' ', 'no', ' ', 'great', ' ', 'surprise', ' ', 'to', ' ', 'me', ' ', 'to', ' ', 'hear', ' ', 'that', ',', ' ', 'in', ' ', 'the', ' ', 'height', ' ', 'of', ' ', 'his', ' ', 'glory', ',', ' ', 'he', ' ', 'had', ' ', 'dropped', ' ', 'his', ' ', 'painting', ',', ' ', 'married', ' ', 'a', ' ', 'rich', ' ', 'widow', ',', ' ', 'and', ' ', 'established', ' ', 'himself', ' ', 'in', ' ', 'a', ' ', 'villa', ' ', 'on', ' ', 'the', ' ', 'Riviera', '.', ' ', '(', 'Though', ' ', 'I', ' ', 'rather', ' ', 'thought', ' ', 'it', ' ', 'would', ' ', 'have', ' ', 'been', ' ', 'Rome', ' ', 'or', ' ', 'Florence', '.', ')', '\\n\\n', '\"', 'The', ' ', 'height', ' ', 'of', ' ', 'his', ' ', 'glory', '\"', '-', '-', 'that', ' ', 'was', ' ', 'what', ' ', 'the', ' ', 'women', ' ', 'called', ' ', 'it', '.', ' ', 'I', ' ', 'can', ' ', 'hear', ' ', 'Mrs', '.', ' ', 'Gideon', ' ', 'Thwing', '-', '-', 'his', ' ', 'last', ' ', 'Chicago', ' ', 'sitter', '-', '-', 'deploring', ' ', 'his', ' ', 'unaccountable', ' ', 'abdication', '.', ' ', '\"', 'Of', ' ', 'course', ' ', 'it', \"'\", 's', ' ', 'going', ' ', 'to', ' ', 'send', ' ', 'the', ' ', 'value', ' ', 'of', ' ', 'my', ' ', 'picture', ' ', \"'\", 'way', ' ', 'up', ';', ' ', 'but', ' ', 'I', ' ', 'don', \"'\", 't', ' ', 'think', ' ', 'of', ' ', 'that', ',', ' ', 'Mr', '.', ' ', 'Rickham', '-', '-', 'the', ' ', 'loss', ' ', 'to', ' ', 'Arrt', ' ', 'is', ' ', 'all', ' ', 'I', ' ', 'think', ' ', 'of', '.', '\"', ' ', 'The', ' ', 'word', ',', ' ', 'on', ' ', 'Mrs', '.', ' ', 'Thwing', \"'\", 's', ' ', 'lips', ',', ' ', 'multiplied', ' ', 'its', ' ', '_rs_', ' ', 'as', ' ', 'though', ' ', 'they', ' ', 'were', ' ', 'reflected', ' ', 'in', ' ', 'an', ' ', 'endless', ' ', 'vista', ' ', 'of', ' ', 'mirrors', '.', ' ', 'And', ' ', 'it', ' ', 'was', ' ', 'not', ' ', 'only', ' ', 'the', ' ', 'Mrs', '.', ' ', 'Thwings', ' ', 'who', ' ', 'mourned', '.', ' ', 'Had', ' ', 'not', ' ', 'the', ' ', 'exquisite', ' ', 'Hermia', ' ', 'Croft', ',', ' ', 'at', ' ', 'the', ' ', 'last', ' ', 'Grafton', ' ', 'Gallery', ' ', 'show', ',', ' ', 'stopped', ' ', 'me', ' ', 'before', ' ', 'Gisburn', \"'\", 's', ' ', '\"', 'Moon', '-', 'dancers', '\"', ' ', 'to', ' ', 'say', ',', ' ', 'with', ' ', 'tears', ' ', 'in', ' ', 'her', ' ', 'eyes', ':', ' ', '\"', 'We', ' ', 'shall', ' ', 'not', ' ', 'look', ' ', 'upon', ' ', 'its', ' ', 'like', ' ', 'again', '\"', '?', '\\n\\n', 'Well', '!', '-', '-', 'even', ' ', 'through', ' ', 'the', ' ', 'prism', ' ', 'of', ' ', 'Hermia', \"'\", 's', ' ', 'tears', ' ', 'I', ' ', 'felt', ' ', 'able', ' ', 'to', ' ', 'face', ' ', 'the', ' ', 'fact', ' ', 'with', ' ', 'equanimity', '.', ' ', 'Poor', ' ', 'Jack', ' ', 'Gisburn', '!', ' ', 'The', ' ', 'women', ' ', 'had', ' ', 'made', ' ', 'him', '-', '-', 'it', ' ', 'was', ' ', 'fitting', ' ', 'that', ' ', 'they', ' ', 'should', ' ', 'mourn', ' ', 'him', '.', ' ', 'Among', ' ', 'his', ' ', 'own', ' ', 'sex', ' ', 'fewer', ' ', 'regrets', ' ', 'were', ' ', 'heard', ',', ' ']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Read the text from the file\n",
    "with open('corpus/the-verdict.txt', 'r', encoding='utf-8') as f:\n",
    "    verdict_text = f.read()\n",
    "\n",
    "# Use regex to split so that every word, whitespace, and special character is a separate token\n",
    "# This will match words, whitespace, or any single non-whitespace, non-word character\n",
    "tokens = re.findall(r'\\w+|\\s+|[^\\w\\s]', verdict_text)\n",
    "\n",
    "# Print the first 50 tokens as a check\n",
    "print(tokens[:500])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72208955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '-', '-', 'though', 'a', 'good', 'fellow', 'enough', '-', '-', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in', 'the', 'height', 'of', 'his', 'glory', ',', 'he', 'had', 'dropped', 'his', 'painting', ',', 'married', 'a', 'rich', 'widow', ',', 'and', 'established', 'himself', 'in', 'a', 'villa', 'on', 'the', 'Riviera', '.', '(', 'Though', 'I', 'rather', 'thought', 'it', 'would', 'have', 'been', 'Rome', 'or', 'Florence', '.', ')', '\"', 'The', 'height', 'of', 'his', 'glory', '\"', '-', '-', 'that', 'was', 'what', 'the', 'women', 'called', 'it', '.', 'I', 'can', 'hear', 'Mrs', '.', 'Gideon', 'Thwing', '-', '-', 'his', 'last', 'Chicago', 'sitter', '-', '-', 'deploring', 'his', 'unaccountable', 'abdication', '.', '\"', 'Of', 'course', 'it', \"'\", 's', 'going', 'to', 'send', 'the', 'value', 'of', 'my', 'picture', \"'\", 'way', 'up', ';', 'but', 'I', 'don', \"'\", 't', 'think', 'of', 'that', ',', 'Mr', '.', 'Rickham', '-', '-', 'the', 'loss', 'to', 'Arrt', 'is', 'all', 'I', 'think', 'of', '.', '\"', 'The', 'word', ',', 'on', 'Mrs', '.', 'Thwing', \"'\", 's', 'lips', ',', 'multiplied', 'its', '_rs_', 'as', 'though', 'they', 'were', 'reflected', 'in', 'an', 'endless', 'vista', 'of', 'mirrors', '.', 'And', 'it', 'was', 'not', 'only', 'the', 'Mrs', '.', 'Thwings', 'who', 'mourned', '.', 'Had', 'not', 'the', 'exquisite', 'Hermia', 'Croft', ',', 'at', 'the', 'last', 'Grafton', 'Gallery', 'show', ',', 'stopped', 'me', 'before', 'Gisburn', \"'\", 's', '\"', 'Moon', '-', 'dancers', '\"', 'to', 'say', ',', 'with', 'tears', 'in', 'her', 'eyes', ':', '\"', 'We', 'shall', 'not', 'look', 'upon', 'its', 'like', 'again', '\"', '?', 'Well', '!', '-', '-', 'even', 'through', 'the', 'prism', 'of', 'Hermia', \"'\", 's', 'tears', 'I', 'felt', 'able', 'to', 'face', 'the', 'fact', 'with', 'equanimity', '.', 'Poor', 'Jack', 'Gisburn', '!', 'The', 'women', 'had', 'made', 'him', '-', '-', 'it', 'was', 'fitting', 'that', 'they', 'should', 'mourn', 'him', '.', 'Among', 'his', 'own', 'sex', 'fewer', 'regrets', 'were', 'heard', ',', 'and', 'in', 'his', 'own', 'trade', 'hardly', 'a', 'murmur', '.', 'Professional', 'jealousy', '?', 'Perhaps', '.', 'If', 'it', 'were', ',', 'the', 'honour', 'of', 'the', 'craft', 'was', 'vindicated', 'by', 'little', 'Claude', 'Nutley', ',', 'who', ',', 'in', 'all', 'good', 'faith', ',', 'brought', 'out', 'in', 'the', 'Burlington', 'a', 'very', 'handsome', '\"', 'obituary', '\"', 'on', 'Jack', '-', '-', 'one', 'of', 'those', 'showy', 'articles', 'stocked', 'with', 'random', 'technicalities', 'that', 'I', 'have', 'heard', '(', 'I', 'won', \"'\", 't', 'say', 'by', 'whom', ')', 'compared', 'to', 'Gisburn', \"'\", 's', 'painting', '.', 'And', 'so', '-', '-', 'his', 'resolve', 'being', 'apparently', 'irrevocable', '-', '-', 'the', 'discussion', 'gradually', 'died', 'out', ',', 'and', ',', 'as', 'Mrs', '.', 'Thwing', 'had', 'predicted', ',', 'the', 'price', 'of', '\"', 'Gisburns', '\"', 'went', 'up', '.', 'It', 'was', 'not', 'till', 'three', 'years', 'later', 'that', ',', 'in', 'the', 'course', 'of', 'a', 'few', 'weeks', \"'\", 'idling', 'on', 'the', 'Riviera', ',', 'it', 'suddenly', 'occurred', 'to', 'me', 'to', 'wonder', 'why', 'Gisburn', 'had', 'given', 'up', 'his', 'painting', '.', 'On', 'reflection', ',', 'it', 'really', 'was', 'a', 'tempting', 'problem', '.', 'To', 'accuse', 'his', 'wife', 'would', 'have', 'been', 'too', 'easy', '-', '-', 'his', 'fair', 'sitters', 'had', 'been', 'denied', 'the', 'solace', 'of', 'saying', 'that', 'Mrs', '.', 'Gisburn', 'had', '\"', 'dragged', 'him', 'down', '.', '\"', 'For', 'Mrs', '.', 'Gisburn', '-', '-', 'as', 'such', '-', '-', 'had', 'not', 'existed', 'till', 'nearly', 'a', 'year']\n"
     ]
    }
   ],
   "source": [
    "tokens_no_whitespace = [token for token in tokens if not token.isspace()]\n",
    "print(tokens_no_whitespace[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34598981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4827"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens_no_whitespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a405b943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 1148\n"
     ]
    }
   ],
   "source": [
    "all_words=sorted(set(tokens_no_whitespace))\n",
    "vocab_size=len(all_words)\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "481bd46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 0), ('\"', 1), (\"'\", 2), ('(', 3), (')', 4), (',', 5), ('-', 6), ('.', 7), (':', 8), (';', 9), ('?', 10), ('A', 11), ('Ah', 12), ('Among', 13), ('And', 14), ('Are', 15), ('Arrt', 16), ('As', 17), ('At', 18), ('Be', 19), ('Begin', 20), ('Burlington', 21), ('But', 22), ('By', 23), ('Carlo', 24), ('Chicago', 25), ('Claude', 26), ('Come', 27), ('Croft', 28), ('Destroyed', 29), ('Devonshire', 30), ('Don', 31), ('Dubarry_', 32), ('Emperors', 33), ('Florence', 34), ('For', 35), ('Gallery', 36), ('Gideon', 37), ('Gisburn', 38), ('Gisburns', 39), ('Grafton', 40), ('Greek', 41), ('Grindle', 42), ('Grindles', 43), ('HAD', 44), ('Had', 45), ('Hang', 46), ('Has', 47), ('He', 48), ('Her', 49)]\n"
     ]
    }
   ],
   "source": [
    "word_to_index = {word: idx for idx, word in enumerate(all_words)}\n",
    "print(list(word_to_index.items())[:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64c0075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "        self.idx_to_str = {idx: word for word, idx in self.str_to_idx.items()}\n",
    "        self.unk_token = \"<unk>\" if \"<unk>\" in self.str_to_idx else None\n",
    "\n",
    "    def encode(self, text):\n",
    "        preprocessed_text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        words = preprocessed_text.split()\n",
    "        if self.unk_token is not None:\n",
    "            return [self.str_to_idx[word] if word in self.str_to_idx else self.str_to_idx[self.unk_token] for word in words]\n",
    "        else:\n",
    "            return [self.str_to_idx[word] for word in words]\n",
    "\n",
    "    def decode(self, ids):\n",
    "        text = ' '.join([self.idx_to_str[idx] if idx in self.idx_to_str else (self.unk_token if self.unk_token is not None else '') for idx in ids])\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f500ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: [53, 530, 163, 1021, 57, 38, 835, 129, 271, 518, 452, 410, 925, 599, 1096, 723, 524, 979, 1034, 676, 1034, 548, 1005, 582, 1006, 551, 736, 562, 514, 546, 530, 388, 562, 762, 674, 129, 858, 1120, 170, 415, 560, 582, 129, 1085, 741, 1006, 84]\n",
      "Decoded: I had always thought Jack Gisburn rather a cheap good fellow enough so it was no great surprise to me to hear that in the height of his glory he had dropped his painting married a rich widow and established himself in a villa on the Riviera\n"
     ]
    }
   ],
   "source": [
    "# Let's test the SimpleTokenizerV1 class with a sample text\n",
    "# Ensure the sample text only contains words from the vocab\n",
    "sample_text = \"I had always thought Jack Gisburn rather a cheap good fellow enough so it was no great surprise to me to hear that in the height of his glory he had dropped his painting married a rich widow and established himself in a villa on the Riviera\"\n",
    "tokenizer = SimpleTokenizerV1(all_words)\n",
    "\n",
    "# Encode the sample text\n",
    "encoded = tokenizer.encode(sample_text)\n",
    "print(\"Encoded:\", encoded)\n",
    "\n",
    "# Decode the encoded ids\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(\"Decoded:\", decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d37dfa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size (with special tokens): 1150\n",
      "Last 5 vocab entries: [('yet', 1143), ('you', 1144), ('younger', 1145), ('your', 1146), ('yourself', 1147)]\n"
     ]
    }
   ],
   "source": [
    "# Add special tokens to the vocabulary and update the mappings\n",
    "special_tokens = ['<eot>', '<unk>']\n",
    "for token in special_tokens:\n",
    "    if token not in all_words:\n",
    "        all_words.append(token)\n",
    "\n",
    "# Update vocab_size\n",
    "vocab_size = len(all_words)\n",
    "print(f\"Vocabulary size (with special tokens): {vocab_size}\")\n",
    "\n",
    "\n",
    "\n",
    "# Show the last few entries to confirm special tokens are present\n",
    "print(\"Last 5 vocab entries:\", list(word_to_index.items())[-5:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "617f5d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, world! a;lkjf i know htat if happens<eot>In the height of his glory, he had dropped his painting, married a rich widow, and established himself in a villa on the Riviera.\n"
     ]
    }
   ],
   "source": [
    "text1='hello, world! a;lkjf i know htat if happens'\n",
    "text2=\"In the height of his glory, he had dropped his painting, married a rich widow, and established himself in a villa on the Riviera.\"\n",
    "\n",
    "text=\"<eot>\".join([text1,text2])\n",
    "print(text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91f8d248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1149, 1149, 1149, 1149, 609, 1149, 580, 1149, 1006, 551, 736, 562, 514, 546, 530, 388, 562, 762, 674, 129, 858, 1120, 170, 415, 560, 582, 129, 1085, 741, 1006, 84]\n"
     ]
    }
   ],
   "source": [
    "tokenizer=SimpleTokenizerV1(all_words)\n",
    "\n",
    "print(tokenizer.encode(text))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3ffed00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\users\\sujith\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.11.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\sujith\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tiktoken) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\sujith\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sujith\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sujith\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sujith\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sujith\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6da7884e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9906, 11, 1917, 0, 578, 6383, 8644, 555, 3279, 411, 1254, 80596, 13] 13\n",
      "Hello, world! The Verdict by Edith Wharton.\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Common choices:\n",
    "# - \"cl100k_base\": used by GPT-4/3.5 Turbo\n",
    "# - \"gpt2\": used by GPT‑2/3 legacy\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "text = \"Hello, world! The Verdict by Edith Wharton.\"\n",
    "ids = enc.encode(text)                 # list of token ids\n",
    "print(ids, len(ids))\n",
    "print(enc.decode(ids))                 # back to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a6a5bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world! The Verdict by Edith Wharton.\n"
     ]
    }
   ],
   "source": [
    "decoded_text = enc.decode(ids)\n",
    "print(decoded_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9bbef0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4943\n"
     ]
    }
   ],
   "source": [
    "with open('corpus/the-verdict.txt', 'r') as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "\n",
    "enc_text=enc.encode(raw_text)\n",
    "print(len(enc_text))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ed3d3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 473, 1846, 2744, 3463, 7762, 480, 285, 22464, 4856, 264, 12136, 35201, 313, 4636, 264, 1695, 12637, 3403, 313, 708, 433, 574, 912, 2294, 13051, 311, 757, 311, 6865, 430, 11, 304, 279, 2673, 315, 813, 27025, 11, 568, 1047, 12504, 813, 19354, 11, 12502, 264, 9257, 57896, 11, 323, 9749, 5678, 304, 264, 47625, 389, 279, 51768, 26919, 13, 320, 27831, 358, 4856, 3463, 433, 1053, 617, 1027, 22463, 477, 48606, 9456, 10227, 2673, 315, 813, 27025, 75857, 9210, 574, 1148, 279, 3278, 2663, 433, 13, 358, 649, 6865, 18083, 13, 480, 100242, 666, 24510, 313, 26301, 1566]\n"
     ]
    }
   ],
   "source": [
    "sample_100 = enc_text[:100]\n",
    "print(sample_100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "67d0f056",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size=4\n",
    "\n",
    "x=enc_text[:context_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "91ffe7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt)  #1\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):  #2\n",
    "            input_chunk = token_ids[i : i + max_length]\n",
    "            target_chunk = token_ids[i + 1 : i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):  #3\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):  #4\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da758490",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=GPTDatasetV1(txt=raw_text,tokenizer=enc,max_length=4,stride=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f1ef64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6cb9fd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9500, -1.7653,  0.2416,  ...,  0.4054,  0.0727,  0.2997],\n",
      "        [ 0.7126, -0.0699,  0.8247,  ...,  2.9777, -0.0623, -0.0431],\n",
      "        [-0.2339,  0.6607, -0.6359,  ..., -2.4909, -1.4999,  0.5544],\n",
      "        ...,\n",
      "        [ 2.0681, -0.7444, -1.5652,  ..., -1.4711, -1.1062, -0.5722],\n",
      "        [-0.3066,  1.3249,  0.8148,  ..., -0.0111,  1.8463, -1.9940],\n",
      "        [-0.3062,  0.4959,  2.7274,  ..., -1.1380, -1.1436, -0.9757]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple embedding layer\n",
    "vocab_size =50257 # assuming enc_text contains all token ids\n",
    "embedding_dim = 256  # you can choose any dimension\n",
    "\n",
    "embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "# Example: get embeddings for the first 10 tokens\n",
    "input_tokens = torch.tensor(enc_text[:10])\n",
    "embeddings = embedding_layer(input_tokens)\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cde40c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Inputs shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length,\n",
    "    stride=max_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"\\nInputs shape:\\n\", inputs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf63adf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings=embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc5e648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72034fdd",
   "metadata": {},
   "source": [
    "absolute embeddings layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "94d37944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7807,  1.2045,  0.6253,  ..., -1.4217, -0.5984,  0.2741],\n",
      "        [-0.3190, -0.2972, -0.6952,  ..., -0.0796,  1.1315,  0.9261],\n",
      "        [ 0.1182, -0.2012,  0.6529,  ..., -0.2330, -1.2454, -0.6015],\n",
      "        [-0.0603,  2.1070,  0.4009,  ...,  0.3823,  1.2538,  1.4545]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "context_length=max_length\n",
    "pos_embedding_layer=torch.nn.Embedding(context_length,embedding_dim)\n",
    "positional_embeddings=pos_embedding_layer(torch.arange(context_length))\n",
    "print(positional_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0f8b19f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings=positional_embeddings+token_embeddings\n",
    "\n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ade8430d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dot(): argument 'tensor' (position 2) must be Tensor, not torch.Size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m attention_scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty(input_embeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, x_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_embeddings[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m----> 5\u001b[0m     attention_scores[i] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(attention_scores)\n",
      "\u001b[1;31mTypeError\u001b[0m: dot(): argument 'tensor' (position 2) must be Tensor, not torch.Size"
     ]
    }
   ],
   "source": [
    "query = input_embeddings.shape\n",
    "attention_scores = torch.empty(input_embeddings.shape[1])\n",
    "\n",
    "for i, x_i in enumerate(input_embeddings[0]):\n",
    "    attention_scores[i] = torch.dot(x_i, query)\n",
    "\n",
    "print(attention_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa87cda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)\n",
      "torch.Size([4, 4])\n",
      "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)\n",
      "torch.Size([4, 4])\n",
      "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)\n",
      "torch.Size([4, 4])\n",
      "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)\n",
      "torch.Size([4, 4])\n",
      "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)\n",
      "torch.Size([4, 4])\n",
      "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)\n",
      "torch.Size([4, 4])\n",
      "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)\n",
      "torch.Size([4, 4])\n",
      "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)\n",
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "query = torch.empty(input_embeddings.shape)\n",
    "query.shape\n",
    "attention_table_col=input_embeddings.shape[1]\n",
    "attention_table_row=input_embeddings.shape[1]\n",
    "attention_scores = torch.empty(8,attention_table_row,attention_table_col)\n",
    "attention_weights = torch.empty(8,attention_table_row,attention_table_col)\n",
    "\n",
    "\n",
    "for i,element in enumerate(input_embeddings):\n",
    "    attention_scores[i]=element@element.T\n",
    "    attention_weights[i]=torch.softmax(attention_scores[i],dim=1)\n",
    "    # print(attention_weights)\n",
    "    print(attention_weights[i].sum(dim=1))\n",
    "    print(attention_weights[i].shape)\n",
    "    # print(attention_weights.shape)\n",
    "    query[i]=attention_weights[i]@element\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fae269",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(72)\n",
    "d_in=256\n",
    "d_out=72\n",
    "W_query=torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "W_key=torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "W_value=torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f537313f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1470,  1.2117,  1.5106,  0.1727, -1.7179,  0.4756,  1.8485, -1.7623,\n",
      "          1.3743, -1.6952, -0.0268, -0.1439,  0.2167, -1.4866, -1.2040,  1.1210,\n",
      "          0.2711, -0.5032,  0.0782, -0.6240, -0.0831, -1.7659,  1.2772,  0.5687,\n",
      "          0.4793, -2.4864, -2.7124,  0.5943,  0.9928, -0.0408, -1.5472, -0.2541,\n",
      "         -0.1865, -1.5792,  0.1732, -0.5570, -2.6253, -0.1595,  0.0720,  0.8394,\n",
      "          1.0381, -1.6998,  0.8757, -0.6407, -0.1187, -0.2671,  1.0992, -1.6783,\n",
      "          0.6972,  1.7765, -3.7969,  1.7232,  1.7697,  1.3824, -1.8205, -1.6900,\n",
      "         -0.4265,  2.5067, -0.1613, -0.6574,  0.7093, -1.9171,  2.9176, -1.5214,\n",
      "          0.7911,  0.2906,  0.0747, -1.9264, -0.8710, -0.7876, -0.0451, -2.1764,\n",
      "          1.3006,  0.1634,  0.5425,  1.4880,  0.2571, -0.2933,  2.0370, -0.2458,\n",
      "         -0.1198,  0.5864,  0.3361,  1.4519,  1.1175, -0.0722, -2.1076,  0.0814,\n",
      "          0.8313, -1.0475, -0.8123, -0.0352, -2.5903, -0.2906, -2.1194, -0.0498,\n",
      "          0.1742, -0.2057, -1.0469,  2.1569,  1.7708,  1.8803, -0.8027, -3.6377,\n",
      "         -0.1563, -1.0051, -0.2511,  0.2601,  0.9720, -1.5515, -0.8769,  2.6130,\n",
      "          2.1776, -0.5776, -0.1676,  0.5909,  0.0148,  2.0052,  0.6609, -2.3852,\n",
      "         -1.0721,  0.7076, -0.9458, -0.5875, -0.5370, -0.6908,  1.8177, -1.6233,\n",
      "         -0.7185, -1.7722,  1.6039, -0.3547,  0.3023, -0.6650,  2.3389,  1.4503,\n",
      "          1.1690, -1.5588, -1.3614,  0.6647, -1.1610,  2.2100, -0.0225,  3.4473,\n",
      "         -2.2855, -1.0369, -0.5178, -1.9355,  1.1895, -0.5997,  2.5148,  1.4493,\n",
      "          0.9617,  1.9280,  1.2753, -1.1108,  2.0656,  3.3466, -1.9058, -1.3774,\n",
      "          0.3119, -2.0868, -1.2315, -2.3058, -0.6906, -0.9101, -0.9298,  1.0429,\n",
      "          1.1104,  0.3544, -0.3252,  0.0299,  0.2701, -1.7114, -0.0624,  1.2718,\n",
      "          2.8440,  1.2193,  0.7200,  1.0670,  1.4771,  0.6138, -2.2987, -0.9216,\n",
      "          1.1756,  2.4116,  1.1034, -0.4987,  0.5678, -1.2957, -2.0299, -1.2554,\n",
      "          1.3482,  1.2053, -0.9211,  1.8551,  1.1148,  0.5419,  0.9706, -1.3042,\n",
      "         -0.6738,  2.5356,  0.1986,  0.7331,  0.3638,  0.1747, -0.5944,  1.0485,\n",
      "          0.3840,  2.5415,  0.9791, -1.2632,  2.7197, -1.2741, -1.4214, -0.0435,\n",
      "         -0.1904,  2.3470, -0.4798, -0.4332,  2.2935, -0.4031,  2.0445, -0.2463,\n",
      "         -0.5865, -0.0871, -0.2345,  0.9413, -0.2015, -1.7440,  0.1246,  0.3765,\n",
      "          1.4986, -0.9969, -0.1644,  1.3365,  0.5805,  0.2673,  0.4742, -0.9020,\n",
      "          0.7696,  0.7488,  0.9491,  0.1527, -1.1658,  0.0230,  0.1058,  0.2755,\n",
      "          2.6305,  0.7136, -1.7836,  0.7963,  0.4492,  2.7506, -0.8562,  0.0327]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_vector = input_embeddings[0][0]\n",
    "print(input_vector.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cd5c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_to_query=input_vector@W_query\n",
    "input_to_key=input_vector@W_key\n",
    "input_to_value=input_vector@W_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0305992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([72])\n"
     ]
    }
   ],
   "source": [
    "print(input_to_query.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8add72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_to_querys=input_embeddings@W_query\n",
    "inputs_to_keys=input_embeddings@W_key\n",
    "inputs_to_values=input_embeddings@W_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896522e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 72])\n",
      "torch.Size([8, 4, 72])\n"
     ]
    }
   ],
   "source": [
    "print(inputs_to_querys.shape)\n",
    "print(inputs_to_keys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2192dfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_key_attention_scores=inputs_to_querys@inputs_to_keys.transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd2e8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "\n",
    "d_k=inputs_to_keys.shape[-1]\n",
    "print(d_k)\n",
    "query_key_attention_scores_normalized=torch.softmax(query_key_attention_scores/d_k**0.5,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36417b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vector=query_key_attention_scores_normalized@inputs_to_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea55d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 72])\n"
     ]
    }
   ],
   "source": [
    "print(context_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6678a965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self,d_in,d_out):\n",
    "        super.__init__()\n",
    "        self.W_query=torch.nn.Parameter(torch.rand(d_in,d_out))\n",
    "        self.W_key=torch.nn.Parameter(torch.rand(d_in,d_out))\n",
    "        self.W_value=torch.nn.Parameter(torch.rand(d_in,d_out))\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        queries=x@self.W_query\n",
    "        keys=x@self.W_key\n",
    "        values=x@self.W_values\n",
    "        \n",
    "        attention_scores=queries@keys.T\n",
    "        attention_weights=torch.softmax(attention_scores/keys.shape[-1]**0.5,dim=-1)\n",
    "        context_vectors=attention_weights@values\n",
    "        return context_vectors\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7516443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Just used nn.Linear for better activation. \n",
    "\n",
    "\n",
    "\n",
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self,d_in,d_out,qkv_bias=False):\n",
    "        super.__init__()\n",
    "        self.W_query=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_key=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_value=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "    def forward(self,X):\n",
    "        queries=x@self.W_query\n",
    "        keys=x@self.W_key\n",
    "        values=x@self.W_values\n",
    "        \n",
    "        attention_scores=queries@keys.T\n",
    "        attention_weight=torch.softmax(attention_scores/keys.shape[-1]**0.5,dim=-1)\n",
    "        context_vectors=attention_weight@values\n",
    "        return context_vectors\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1c7be28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "    def __init__(self,d_in,d_out,qkv_bias=False):\n",
    "        super.__init__()\n",
    "        self.W_query=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_key=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_value=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        queries=x@self.W_query\n",
    "        keys=x@self.W_key\n",
    "        values=x@self.W_value\n",
    "        \n",
    "        attention_scores=queries@keys.T\n",
    "        mask=torch.ones(attention_scores.shape[0],attention_scores.shape[1])\n",
    "        mask=torch.triu(mask)\n",
    "        attention_scores[mask==1]=torch.tensor(-float('inf'))\n",
    "        attention_weight=torch.softmax(attention_scores/keys.shape[-1]**0.5,dim=-1)\n",
    "        # drop out here\n",
    "        # The 'train' parameter specifies whether dropout should behave in training mode (drop values) or evaluation mode (no dropout).\n",
    "        # In PyTorch, when train=True, dropout is applied; when train=False, dropout is bypassed.\n",
    "        attention_weight = torch.dropout(attention_weight, p=0.5, train=self.training)\n",
    "        context_vectors=attention_weight@values\n",
    "        return context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "970323e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "    def __init__(self,d_in,d_out,context_length,drop_out,num_heads,qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads=nn.ModuleList([CausalAttention(d_in,d_out,context_length,drop_out,qkv_bias)for _ in range(num_heads)])\n",
    "    def forward(self,x):\n",
    "        return torch.cat([head(x) for head in self.heads],dim=-1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "77f6a10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,d_in,d_out,context_length,drop_out,num_heads,qkv_bias=False):\n",
    "        super.__init__()\n",
    "        assert d_out % num_heads==0, \"d_out must be divisible by num_heads\"\n",
    "        self.W_query=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_key=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_value=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.head_dim=d_out//num_heads\n",
    "        self.drop_out=nn.Dropout(drop_out)\n",
    "        self.out_proj=nn.Linear(d_out,d_out)\n",
    "        self.num_heads=num_heads\n",
    "        self.register_buffer(\"mask\",torch.triu(torch.ones(context_length,context_length),diagonal=1))\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        b,num_of_token,d_in=x.shape\n",
    "        keys=self.W_key(x)\n",
    "        values=self.W_value(x)\n",
    "        queries=self.W_query(x)\n",
    "        \n",
    "        keys=keys.view(b,num_of_token,self.num_heads,self.head_dim)\n",
    "        queries=queries.view(b,num_of_token,self.num_heads,self.head_dim)\n",
    "        values=values.view(b,num_of_token,self.num_heads,self.head_dim)\n",
    "        \n",
    "        \n",
    "        keys.transpose(1,2)\n",
    "        values.transpose(1,2)\n",
    "        queries.transpose(1,2)\n",
    "        \n",
    "        attention_score=queries@keys.tranpose(2,3)\n",
    "        mask_bool=self.mask.bool()[:num_of_token,:num_of_token]\n",
    "        attention_score.fill(mask_bool,-torch.inf)\n",
    "        \n",
    "        attention_weights=torch.softmax(attention_score/keys.shape[-1]**2,dim=-1)\n",
    "        attention_weights=self.drop_out(attention_weights)\n",
    "        \n",
    "        context_vector=(attention_weights@values).transpose(1,2)\n",
    "        \n",
    "        context_vector=context_vector.contiguous().view(b,num_of_token,self.d_out)\n",
    "        \n",
    "        context_vector=self.out_proj(context_vector)\n",
    "        \n",
    "        return context_vector\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76277403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde47cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21f13a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d31c61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "for i,x_i in enumerate(input_embeddings[0]):\n",
    "    print(x_i.shape)\n",
    "    context_vectors[i]=attention_weight_using_softmax[i]*x_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eab662",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "len() of a 0-d tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[164], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_vector\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_tensor.py:1164\u001b[0m, in \u001b[0;36mTensor.__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlen() of a 0-d tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state():\n\u001b[0;32m   1166\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing len to get tensor shape might cause the trace to be incorrect. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1168\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecommended usage would be tensor.shape[0]. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1172\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1173\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: len() of a 0-d tensor"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190b8af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 46.8761, 494.9998,  -4.3935,  38.6101], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d012af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b3c2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeddings[0][0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caea59a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc7aa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights=attention_scores/attention_scores.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5634e75b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35851df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0814,  0.8592, -0.0076,  0.0670], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0257b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b68a452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_max_naive(x):\n",
    "    return torch.exp(x)/torch.exp(x).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a532f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output tensor([0., nan, 0., 0.], grad_fn=<DivBackward0>) happened because the denominator in soft_max_naive was zero or very close to zero.\n",
    "# Given your attention_scores are tensor([ 46.8761, 494.9998,  -4.3935,  38.6101]), torch.exp(attention_scores) will be extremely large for 494.9998,\n",
    "# and almost zero for the others, causing the sum to be dominated by one value and the rest to underflow.\n",
    "# This can cause numerical instability and nan values.\n",
    "# To fix this, use a numerically stable softmax:\n",
    "def soft_max_stable(x):\n",
    "    x_exp = torch.exp(x - x.max())\n",
    "    return x_exp / x_exp.sum(dim=0)\n",
    "\n",
    "attention_weight_using_softmax = soft_max_stable(attention_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6e2838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0.], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(attention_weight_using_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc13c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 0.], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need dim=0 here because attention_scores is a 1D tensor (a vector), and softmax needs to know along which dimension to compute the softmax.\n",
    "# For a vector, dim=0 means we apply softmax over the entire vector.\n",
    "torch.softmax(attention_scores, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5889da69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1470,  1.2117,  1.5106,  ...,  2.7506, -0.8562,  0.0327],\n",
      "        [-0.8444,  1.3840,  0.2867,  ...,  1.0948,  0.3536, -2.5692],\n",
      "        [-2.0449, -2.3660, -1.3700,  ...,  2.1413,  0.9736, -0.2204],\n",
      "        [-0.9697, -1.1252, -1.6693,  ..., -1.6593,  0.7941,  1.6137]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "query=input_embeddings[0]\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8048151",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vectors=torch.zeros(query.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fa582e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a86843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "for i,x_i in enumerate(input_embeddings[0]):\n",
    "    print(x_i.shape)\n",
    "    context_vectors[i]=attention_weight_using_softmax[i]*x_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb85dc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "        [-0.8444,  1.3840,  0.2867,  ...,  1.0948,  0.3536, -2.5692],\n",
       "        [-0.0000, -0.0000, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
       "        [-0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.0000]],\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09991800",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
