{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4dc401b",
   "metadata": {},
   "source": [
    "Word Embedding chapter 2.1 assignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36a88fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters in the file: 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g\n"
     ]
    }
   ],
   "source": [
    "with open('corpus/the-verdict.txt', 'r', encoding='utf-8') as file:\n",
    "    raw_text = file.read()\n",
    "print(\"Total number of characters in the file:\", len(raw_text))\n",
    "print(raw_text[:100])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10513aa4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cf43e497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello,', ' ', 'world!', ' ', 'a;lkjf', ' ', 'i', ' ', 'know', ' ', 'htat', ' ', 'if', ' ', 'happens']\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "text='hello, world! a;lkjf i know htat if happens'\n",
    "result=re.split(r'(\\s)',text)\n",
    "print(result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "79e0957c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', ',', '', ' ', 'world!', ' ', 'a', ';', 'lkjf', ' ', 'i', ' ', 'know', ' ', 'htat', ' ', 'if', ' ', 'happens']\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "text='hello, world! a;lkjf i know htat if happens'\n",
    "result2=re.split(r'([\\s,;])',text)\n",
    "print(result2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ef9ce03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', ' ', 'HAD', ' ', 'always', ' ', 'thought', ' ', 'Jack', ' ', 'Gisburn', ' ', 'rather', ' ', 'a', ' ', 'cheap', ' ', 'genius', '-', '-', 'though', ' ', 'a', ' ', 'good', ' ', 'fellow', ' ', 'enough', '-', '-', 'so', ' ', 'it', ' ', 'was', ' ', 'no', ' ', 'great', ' ', 'surprise', ' ', 'to', ' ', 'me', ' ', 'to', ' ', 'hear', ' ', 'that', ',', ' ', 'in', ' ', 'the', ' ', 'height', ' ', 'of', ' ', 'his', ' ', 'glory', ',', ' ', 'he', ' ', 'had', ' ', 'dropped', ' ', 'his', ' ', 'painting', ',', ' ', 'married', ' ', 'a', ' ', 'rich', ' ', 'widow', ',', ' ', 'and', ' ', 'established', ' ', 'himself', ' ', 'in', ' ', 'a', ' ', 'villa', ' ', 'on', ' ', 'the', ' ', 'Riviera', '.', ' ', '(', 'Though', ' ', 'I', ' ', 'rather', ' ', 'thought', ' ', 'it', ' ', 'would', ' ', 'have', ' ', 'been', ' ', 'Rome', ' ', 'or', ' ', 'Florence', '.', ')', '\\n\\n', '\"', 'The', ' ', 'height', ' ', 'of', ' ', 'his', ' ', 'glory', '\"', '-', '-', 'that', ' ', 'was', ' ', 'what', ' ', 'the', ' ', 'women', ' ', 'called', ' ', 'it', '.', ' ', 'I', ' ', 'can', ' ', 'hear', ' ', 'Mrs', '.', ' ', 'Gideon', ' ', 'Thwing', '-', '-', 'his', ' ', 'last', ' ', 'Chicago', ' ', 'sitter', '-', '-', 'deploring', ' ', 'his', ' ', 'unaccountable', ' ', 'abdication', '.', ' ', '\"', 'Of', ' ', 'course', ' ', 'it', \"'\", 's', ' ', 'going', ' ', 'to', ' ', 'send', ' ', 'the', ' ', 'value', ' ', 'of', ' ', 'my', ' ', 'picture', ' ', \"'\", 'way', ' ', 'up', ';', ' ', 'but', ' ', 'I', ' ', 'don', \"'\", 't', ' ', 'think', ' ', 'of', ' ', 'that', ',', ' ', 'Mr', '.', ' ', 'Rickham', '-', '-', 'the', ' ', 'loss', ' ', 'to', ' ', 'Arrt', ' ', 'is', ' ', 'all', ' ', 'I', ' ', 'think', ' ', 'of', '.', '\"', ' ', 'The', ' ', 'word', ',', ' ', 'on', ' ', 'Mrs', '.', ' ', 'Thwing', \"'\", 's', ' ', 'lips', ',', ' ', 'multiplied', ' ', 'its', ' ', '_rs_', ' ', 'as', ' ', 'though', ' ', 'they', ' ', 'were', ' ', 'reflected', ' ', 'in', ' ', 'an', ' ', 'endless', ' ', 'vista', ' ', 'of', ' ', 'mirrors', '.', ' ', 'And', ' ', 'it', ' ', 'was', ' ', 'not', ' ', 'only', ' ', 'the', ' ', 'Mrs', '.', ' ', 'Thwings', ' ', 'who', ' ', 'mourned', '.', ' ', 'Had', ' ', 'not', ' ', 'the', ' ', 'exquisite', ' ', 'Hermia', ' ', 'Croft', ',', ' ', 'at', ' ', 'the', ' ', 'last', ' ', 'Grafton', ' ', 'Gallery', ' ', 'show', ',', ' ', 'stopped', ' ', 'me', ' ', 'before', ' ', 'Gisburn', \"'\", 's', ' ', '\"', 'Moon', '-', 'dancers', '\"', ' ', 'to', ' ', 'say', ',', ' ', 'with', ' ', 'tears', ' ', 'in', ' ', 'her', ' ', 'eyes', ':', ' ', '\"', 'We', ' ', 'shall', ' ', 'not', ' ', 'look', ' ', 'upon', ' ', 'its', ' ', 'like', ' ', 'again', '\"', '?', '\\n\\n', 'Well', '!', '-', '-', 'even', ' ', 'through', ' ', 'the', ' ', 'prism', ' ', 'of', ' ', 'Hermia', \"'\", 's', ' ', 'tears', ' ', 'I', ' ', 'felt', ' ', 'able', ' ', 'to', ' ', 'face', ' ', 'the', ' ', 'fact', ' ', 'with', ' ', 'equanimity', '.', ' ', 'Poor', ' ', 'Jack', ' ', 'Gisburn', '!', ' ', 'The', ' ', 'women', ' ', 'had', ' ', 'made', ' ', 'him', '-', '-', 'it', ' ', 'was', ' ', 'fitting', ' ', 'that', ' ', 'they', ' ', 'should', ' ', 'mourn', ' ', 'him', '.', ' ', 'Among', ' ', 'his', ' ', 'own', ' ', 'sex', ' ', 'fewer', ' ', 'regrets', ' ', 'were', ' ', 'heard', ',', ' ']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Read the text from the file\n",
    "with open('corpus/the-verdict.txt', 'r', encoding='utf-8') as f:\n",
    "    verdict_text = f.read()\n",
    "\n",
    "# Use regex to split so that every word, whitespace, and special character is a separate token\n",
    "# This will match words, whitespace, or any single non-whitespace, non-word character\n",
    "tokens = re.findall(r'\\w+|\\s+|[^\\w\\s]', verdict_text)\n",
    "\n",
    "# Print the first 50 tokens as a check\n",
    "print(tokens[:500])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "72208955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '-', '-', 'though', 'a', 'good', 'fellow', 'enough', '-', '-', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in', 'the', 'height', 'of', 'his', 'glory', ',', 'he', 'had', 'dropped', 'his', 'painting', ',', 'married', 'a', 'rich', 'widow', ',', 'and', 'established', 'himself', 'in', 'a', 'villa', 'on', 'the', 'Riviera', '.', '(', 'Though', 'I', 'rather', 'thought', 'it', 'would', 'have', 'been', 'Rome', 'or', 'Florence', '.', ')', '\"', 'The', 'height', 'of', 'his', 'glory', '\"', '-', '-', 'that', 'was', 'what', 'the', 'women', 'called', 'it', '.', 'I', 'can', 'hear', 'Mrs', '.', 'Gideon', 'Thwing', '-', '-', 'his', 'last', 'Chicago', 'sitter', '-', '-', 'deploring', 'his', 'unaccountable', 'abdication', '.', '\"', 'Of', 'course', 'it', \"'\", 's', 'going', 'to', 'send', 'the', 'value', 'of', 'my', 'picture', \"'\", 'way', 'up', ';', 'but', 'I', 'don', \"'\", 't', 'think', 'of', 'that', ',', 'Mr', '.', 'Rickham', '-', '-', 'the', 'loss', 'to', 'Arrt', 'is', 'all', 'I', 'think', 'of', '.', '\"', 'The', 'word', ',', 'on', 'Mrs', '.', 'Thwing', \"'\", 's', 'lips', ',', 'multiplied', 'its', '_rs_', 'as', 'though', 'they', 'were', 'reflected', 'in', 'an', 'endless', 'vista', 'of', 'mirrors', '.', 'And', 'it', 'was', 'not', 'only', 'the', 'Mrs', '.', 'Thwings', 'who', 'mourned', '.', 'Had', 'not', 'the', 'exquisite', 'Hermia', 'Croft', ',', 'at', 'the', 'last', 'Grafton', 'Gallery', 'show', ',', 'stopped', 'me', 'before', 'Gisburn', \"'\", 's', '\"', 'Moon', '-', 'dancers', '\"', 'to', 'say', ',', 'with', 'tears', 'in', 'her', 'eyes', ':', '\"', 'We', 'shall', 'not', 'look', 'upon', 'its', 'like', 'again', '\"', '?', 'Well', '!', '-', '-', 'even', 'through', 'the', 'prism', 'of', 'Hermia', \"'\", 's', 'tears', 'I', 'felt', 'able', 'to', 'face', 'the', 'fact', 'with', 'equanimity', '.', 'Poor', 'Jack', 'Gisburn', '!', 'The', 'women', 'had', 'made', 'him', '-', '-', 'it', 'was', 'fitting', 'that', 'they', 'should', 'mourn', 'him', '.', 'Among', 'his', 'own', 'sex', 'fewer', 'regrets', 'were', 'heard', ',', 'and', 'in', 'his', 'own', 'trade', 'hardly', 'a', 'murmur', '.', 'Professional', 'jealousy', '?', 'Perhaps', '.', 'If', 'it', 'were', ',', 'the', 'honour', 'of', 'the', 'craft', 'was', 'vindicated', 'by', 'little', 'Claude', 'Nutley', ',', 'who', ',', 'in', 'all', 'good', 'faith', ',', 'brought', 'out', 'in', 'the', 'Burlington', 'a', 'very', 'handsome', '\"', 'obituary', '\"', 'on', 'Jack', '-', '-', 'one', 'of', 'those', 'showy', 'articles', 'stocked', 'with', 'random', 'technicalities', 'that', 'I', 'have', 'heard', '(', 'I', 'won', \"'\", 't', 'say', 'by', 'whom', ')', 'compared', 'to', 'Gisburn', \"'\", 's', 'painting', '.', 'And', 'so', '-', '-', 'his', 'resolve', 'being', 'apparently', 'irrevocable', '-', '-', 'the', 'discussion', 'gradually', 'died', 'out', ',', 'and', ',', 'as', 'Mrs', '.', 'Thwing', 'had', 'predicted', ',', 'the', 'price', 'of', '\"', 'Gisburns', '\"', 'went', 'up', '.', 'It', 'was', 'not', 'till', 'three', 'years', 'later', 'that', ',', 'in', 'the', 'course', 'of', 'a', 'few', 'weeks', \"'\", 'idling', 'on', 'the', 'Riviera', ',', 'it', 'suddenly', 'occurred', 'to', 'me', 'to', 'wonder', 'why', 'Gisburn', 'had', 'given', 'up', 'his', 'painting', '.', 'On', 'reflection', ',', 'it', 'really', 'was', 'a', 'tempting', 'problem', '.', 'To', 'accuse', 'his', 'wife', 'would', 'have', 'been', 'too', 'easy', '-', '-', 'his', 'fair', 'sitters', 'had', 'been', 'denied', 'the', 'solace', 'of', 'saying', 'that', 'Mrs', '.', 'Gisburn', 'had', '\"', 'dragged', 'him', 'down', '.', '\"', 'For', 'Mrs', '.', 'Gisburn', '-', '-', 'as', 'such', '-', '-', 'had', 'not', 'existed', 'till', 'nearly', 'a', 'year']\n"
     ]
    }
   ],
   "source": [
    "tokens_no_whitespace = [token for token in tokens if not token.isspace()]\n",
    "print(tokens_no_whitespace[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "34598981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4827"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens_no_whitespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a405b943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 1148\n"
     ]
    }
   ],
   "source": [
    "all_words=sorted(set(tokens_no_whitespace))\n",
    "vocab_size=len(all_words)\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "481bd46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 0), ('\"', 1), (\"'\", 2), ('(', 3), (')', 4), (',', 5), ('-', 6), ('.', 7), (':', 8), (';', 9), ('?', 10), ('A', 11), ('Ah', 12), ('Among', 13), ('And', 14), ('Are', 15), ('Arrt', 16), ('As', 17), ('At', 18), ('Be', 19), ('Begin', 20), ('Burlington', 21), ('But', 22), ('By', 23), ('Carlo', 24), ('Chicago', 25), ('Claude', 26), ('Come', 27), ('Croft', 28), ('Destroyed', 29), ('Devonshire', 30), ('Don', 31), ('Dubarry_', 32), ('Emperors', 33), ('Florence', 34), ('For', 35), ('Gallery', 36), ('Gideon', 37), ('Gisburn', 38), ('Gisburns', 39), ('Grafton', 40), ('Greek', 41), ('Grindle', 42), ('Grindles', 43), ('HAD', 44), ('Had', 45), ('Hang', 46), ('Has', 47), ('He', 48), ('Her', 49)]\n"
     ]
    }
   ],
   "source": [
    "word_to_index = {word: idx for idx, word in enumerate(all_words)}\n",
    "print(list(word_to_index.items())[:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "64c0075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "        self.idx_to_str = {idx: word for word, idx in self.str_to_idx.items()}\n",
    "        self.unk_token = \"<unk>\" if \"<unk>\" in self.str_to_idx else None\n",
    "\n",
    "    def encode(self, text):\n",
    "        preprocessed_text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        words = preprocessed_text.split()\n",
    "        if self.unk_token is not None:\n",
    "            return [self.str_to_idx[word] if word in self.str_to_idx else self.str_to_idx[self.unk_token] for word in words]\n",
    "        else:\n",
    "            return [self.str_to_idx[word] for word in words]\n",
    "\n",
    "    def decode(self, ids):\n",
    "        text = ' '.join([self.idx_to_str[idx] if idx in self.idx_to_str else (self.unk_token if self.unk_token is not None else '') for idx in ids])\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f500ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: [53, 530, 163, 1021, 57, 38, 835, 129, 271, 518, 452, 410, 925, 599, 1096, 723, 524, 979, 1034, 676, 1034, 548, 1005, 582, 1006, 551, 736, 562, 514, 546, 530, 388, 562, 762, 674, 129, 858, 1120, 170, 415, 560, 582, 129, 1085, 741, 1006, 84]\n",
      "Decoded: I had always thought Jack Gisburn rather a cheap good fellow enough so it was no great surprise to me to hear that in the height of his glory he had dropped his painting married a rich widow and established himself in a villa on the Riviera\n"
     ]
    }
   ],
   "source": [
    "# Let's test the SimpleTokenizerV1 class with a sample text\n",
    "# Ensure the sample text only contains words from the vocab\n",
    "sample_text = \"I had always thought Jack Gisburn rather a cheap good fellow enough so it was no great surprise to me to hear that in the height of his glory he had dropped his painting married a rich widow and established himself in a villa on the Riviera\"\n",
    "tokenizer = SimpleTokenizerV1(all_words)\n",
    "\n",
    "# Encode the sample text\n",
    "encoded = tokenizer.encode(sample_text)\n",
    "print(\"Encoded:\", encoded)\n",
    "\n",
    "# Decode the encoded ids\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(\"Decoded:\", decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d37dfa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size (with special tokens): 1150\n",
      "Last 5 vocab entries: [('yet', 1143), ('you', 1144), ('younger', 1145), ('your', 1146), ('yourself', 1147)]\n"
     ]
    }
   ],
   "source": [
    "# Add special tokens to the vocabulary and update the mappings\n",
    "special_tokens = ['<eot>', '<unk>']\n",
    "for token in special_tokens:\n",
    "    if token not in all_words:\n",
    "        all_words.append(token)\n",
    "\n",
    "# Update vocab_size\n",
    "vocab_size = len(all_words)\n",
    "print(f\"Vocabulary size (with special tokens): {vocab_size}\")\n",
    "\n",
    "\n",
    "\n",
    "# Show the last few entries to confirm special tokens are present\n",
    "print(\"Last 5 vocab entries:\", list(word_to_index.items())[-5:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "617f5d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, world! a;lkjf i know htat if happens<eot>In the height of his glory, he had dropped his painting, married a rich widow, and established himself in a villa on the Riviera.\n"
     ]
    }
   ],
   "source": [
    "text1='hello, world! a;lkjf i know htat if happens'\n",
    "text2=\"In the height of his glory, he had dropped his painting, married a rich widow, and established himself in a villa on the Riviera.\"\n",
    "\n",
    "text=\"<eot>\".join([text1,text2])\n",
    "print(text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "91f8d248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1149, 1149, 1149, 1149, 609, 1149, 580, 1149, 1006, 551, 736, 562, 514, 546, 530, 388, 562, 762, 674, 129, 858, 1120, 170, 415, 560, 582, 129, 1085, 741, 1006, 84]\n"
     ]
    }
   ],
   "source": [
    "tokenizer=SimpleTokenizerV1(all_words)\n",
    "\n",
    "print(tokenizer.encode(text))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6da7884e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9906, 11, 1917, 0, 578, 6383, 8644, 555, 3279, 411, 1254, 80596, 13] 13\n",
      "Hello, world! The Verdict by Edith Wharton.\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Common choices:\n",
    "# - \"cl100k_base\": used by GPT-4/3.5 Turbo\n",
    "# - \"gpt2\": used by GPTâ€‘2/3 legacy\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "text = \"Hello, world! The Verdict by Edith Wharton.\"\n",
    "ids = enc.encode(text)                 # list of token ids\n",
    "print(ids, len(ids))\n",
    "print(enc.decode(ids))                 # back to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7a6a5bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world! The Verdict by Edith Wharton.\n"
     ]
    }
   ],
   "source": [
    "decoded_text = enc.decode(ids)\n",
    "print(decoded_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9bbef0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4943\n"
     ]
    }
   ],
   "source": [
    "with open('corpus/the-verdict.txt', 'r') as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "\n",
    "enc_text=enc.encode(raw_text)\n",
    "print(len(enc_text))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2ed3d3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 473, 1846, 2744, 3463, 7762, 480, 285, 22464, 4856, 264, 12136, 35201, 313, 4636, 264, 1695, 12637, 3403, 313, 708, 433, 574, 912, 2294, 13051, 311, 757, 311, 6865, 430, 11, 304, 279, 2673, 315, 813, 27025, 11, 568, 1047, 12504, 813, 19354, 11, 12502, 264, 9257, 57896, 11, 323, 9749, 5678, 304, 264, 47625, 389, 279, 51768, 26919, 13, 320, 27831, 358, 4856, 3463, 433, 1053, 617, 1027, 22463, 477, 48606, 9456, 10227, 2673, 315, 813, 27025, 75857, 9210, 574, 1148, 279, 3278, 2663, 433, 13, 358, 649, 6865, 18083, 13, 480, 100242, 666, 24510, 313, 26301, 1566]\n"
     ]
    }
   ],
   "source": [
    "sample_100 = enc_text[:100]\n",
    "print(sample_100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "67d0f056",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size=4\n",
    "\n",
    "x=enc_text[:context_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "91ffe7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt)  #1\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):  #2\n",
    "            input_chunk = token_ids[i : i + max_length]\n",
    "            target_chunk = token_ids[i + 1 : i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):  #3\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):  #4\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "da758490",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=GPTDatasetV1(txt=raw_text,tokenizer=enc,max_length=4,stride=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7f1ef64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6cb9fd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8344, -1.0225, -0.8531,  ...,  0.4846,  1.9862,  1.2526],\n",
      "        [ 0.2087, -0.6060,  0.8480,  ...,  1.0472,  0.9735, -0.7083],\n",
      "        [-0.0217, -0.6680,  0.1606,  ..., -0.4493,  0.2942,  0.4851],\n",
      "        ...,\n",
      "        [ 0.4886,  2.1469, -0.8107,  ..., -1.6966,  0.4089, -2.8211],\n",
      "        [ 2.5293,  0.4575,  2.2196,  ..., -1.7357,  1.4130,  0.2255],\n",
      "        [-0.9635, -1.1634,  0.5515,  ..., -1.3202, -0.2547, -1.2055]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple embedding layer\n",
    "vocab_size =50257 # assuming enc_text contains all token ids\n",
    "embedding_dim = 256  # you can choose any dimension\n",
    "\n",
    "embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "# Example: get embeddings for the first 10 tokens\n",
    "input_tokens = torch.tensor(enc_text[:10])\n",
    "embeddings = embedding_layer(input_tokens)\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cde40c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Inputs shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length,\n",
    "    stride=max_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"\\nInputs shape:\\n\", inputs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bf63adf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings=embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc5e648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72034fdd",
   "metadata": {},
   "source": [
    "absolute embeddings layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "94d37944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3946,  0.4274, -2.3213,  ..., -0.1984, -1.4348,  0.0411],\n",
      "        [ 0.5909,  0.8927, -0.6213,  ...,  1.7454,  0.3711,  0.7022],\n",
      "        [-0.5403,  1.4951,  1.4297,  ...,  0.5007,  0.7117,  0.6698],\n",
      "        [ 0.1909,  1.1373, -0.5982,  ...,  0.0581, -1.8555, -0.6455]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "context_length=max_length\n",
    "pos_embedding_layer=torch.nn.Embedding(context_length,embedding_dim)\n",
    "positional_embeddings=pos_embedding_layer(torch.arange(context_length))\n",
    "print(positional_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0f8b19f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings=positional_embeddings+token_embeddings\n",
    "\n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aa87cda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)\n",
      "torch.Size([4, 4])\n",
      "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)\n",
      "torch.Size([4, 4])\n",
      "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)\n",
      "torch.Size([4, 4])\n",
      "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)\n",
      "torch.Size([4, 4])\n",
      "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)\n",
      "torch.Size([4, 4])\n",
      "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)\n",
      "torch.Size([4, 4])\n",
      "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)\n",
      "torch.Size([4, 4])\n",
      "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)\n",
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "query = torch.empty(input_embeddings.shape)\n",
    "query.shape\n",
    "attention_table_col=input_embeddings.shape[1]\n",
    "attention_table_row=input_embeddings.shape[1]\n",
    "attention_scores = torch.empty(8,attention_table_row,attention_table_col)\n",
    "attention_weights = torch.empty(8,attention_table_row,attention_table_col)\n",
    "\n",
    "\n",
    "for i,element in enumerate(input_embeddings):\n",
    "    attention_scores[i]=element@element.T\n",
    "    attention_weights[i]=torch.softmax(attention_scores[i],dim=1)\n",
    "    # print(attention_weights)\n",
    "    print(attention_weights[i].sum(dim=1))\n",
    "    print(attention_weights[i].shape)\n",
    "    # print(attention_weights.shape)\n",
    "    query[i]=attention_weights[i]@element\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "72fae269",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(72)\n",
    "d_in=256\n",
    "d_out=72\n",
    "W_query=torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "W_key=torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "W_value=torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f537313f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2290e+00, -5.9509e-01, -3.1744e+00, -3.0316e+00, -6.3213e-01,\n",
      "          5.8722e-01,  1.3980e+00,  7.9777e-01, -8.8286e-02, -1.5712e+00,\n",
      "          7.2113e-01,  2.9131e-01, -7.5297e-01,  2.2121e+00,  2.3546e+00,\n",
      "         -2.6200e+00, -6.5233e-01, -7.1504e-01,  1.2777e+00,  1.0399e+00,\n",
      "         -1.0511e+00,  2.5253e+00,  7.4948e-01,  2.4135e-01, -9.1394e-02,\n",
      "          1.1588e+00,  2.7922e-01, -3.9609e-01, -2.1079e+00,  1.4400e+00,\n",
      "         -3.5792e-01,  7.9199e-01, -1.9630e+00, -9.8013e-01,  1.0177e+00,\n",
      "          8.6998e-01, -3.1544e-01, -5.9904e-01,  3.7691e-01,  1.6524e+00,\n",
      "         -1.5082e+00,  3.7887e-01,  3.0447e-01, -3.2149e-02,  7.6003e-01,\n",
      "          1.1566e+00,  6.1509e-01,  9.0333e-02,  1.8972e+00,  3.2017e+00,\n",
      "          3.4993e-02,  3.4410e-01, -4.0470e-01,  3.2788e-01, -1.8356e+00,\n",
      "          1.8804e-01, -1.2250e-01,  1.0389e+00,  1.2796e+00,  2.7727e+00,\n",
      "          1.0089e+00, -1.6401e+00, -1.7382e+00, -1.6241e-01, -1.6881e+00,\n",
      "         -1.1662e+00, -8.1370e-01,  5.6937e-01,  1.4316e+00,  4.8825e-01,\n",
      "         -1.2303e+00, -6.5733e-02, -1.3388e+00,  9.3639e-01,  1.4494e+00,\n",
      "          8.7704e-01, -5.4515e-01,  8.0919e-01, -7.4829e-01,  9.6327e-01,\n",
      "         -1.6075e+00,  2.9616e-02,  6.1324e-01, -9.3536e-01,  1.6177e+00,\n",
      "          1.6509e-01,  1.4516e+00, -1.6951e+00,  4.8955e-02, -2.9963e-01,\n",
      "         -1.5340e+00,  1.9390e-01, -1.1189e+00,  5.9173e-01,  2.7644e-01,\n",
      "          1.4915e+00, -9.9056e-01, -2.2297e-01,  1.5907e+00, -5.6611e-01,\n",
      "         -1.1359e-01, -1.0942e+00,  7.1667e-01,  6.5184e-02, -2.1064e+00,\n",
      "          2.3887e-01,  6.4309e-01, -1.6203e+00, -8.1837e-01, -3.3819e-01,\n",
      "          1.6741e+00,  1.5941e+00,  4.3104e-01, -1.3301e+00, -7.6396e-01,\n",
      "          1.3277e+00, -1.0902e-01, -5.6423e-01, -8.5580e-01, -2.5212e+00,\n",
      "          6.3032e-01, -7.9131e-02, -3.7264e-01,  2.7799e-01,  1.5650e+00,\n",
      "         -7.2304e-01, -4.7898e-01, -6.1336e-01,  5.3167e-01,  1.9567e+00,\n",
      "          9.7403e-01,  1.6265e+00,  2.5614e+00, -1.4557e+00,  1.0876e+00,\n",
      "         -7.3993e-01,  1.3653e+00,  1.3940e+00, -1.8539e+00, -4.4517e-01,\n",
      "          8.6187e-01, -2.4368e+00, -8.5802e-01, -1.8160e+00,  1.9110e-02,\n",
      "          1.4275e+00,  6.5661e-02, -3.0960e+00, -2.9742e+00,  3.0048e-01,\n",
      "          1.7690e+00, -1.4366e+00,  8.0949e-02,  2.5596e+00, -2.4318e-02,\n",
      "          1.3870e+00, -1.2804e+00,  5.5602e-01,  1.8987e-01,  2.3909e+00,\n",
      "          1.6836e-02, -7.7221e-01, -1.0402e+00,  1.9980e+00, -2.8341e+00,\n",
      "         -1.4773e+00, -1.1690e+00,  1.0643e+00,  3.1145e-01, -5.1348e-02,\n",
      "         -1.2511e+00,  1.0808e+00,  1.3258e+00, -3.8746e-01, -1.2440e+00,\n",
      "          1.0910e+00,  4.6267e-01, -1.3468e+00, -1.9200e-01,  1.7288e+00,\n",
      "          3.1175e-01,  2.0227e+00,  7.3393e-02, -3.6839e-01,  1.3569e+00,\n",
      "          2.4468e+00,  8.5352e-01, -1.3517e+00,  2.0483e-01, -2.0109e+00,\n",
      "         -6.2319e-01, -2.5110e+00, -1.0001e+00, -1.5821e-01,  1.6422e-01,\n",
      "          1.3124e+00,  1.4723e-01,  8.0931e-01,  1.6672e+00, -3.0327e-04,\n",
      "          2.7662e+00,  5.9861e-01, -1.7810e+00,  4.7190e-01, -1.3439e+00,\n",
      "         -1.0775e+00,  6.0094e-01, -5.7176e-01, -2.0829e+00,  3.0999e-01,\n",
      "          4.7618e-01,  2.9943e+00, -7.7249e-01,  1.8497e+00, -1.7107e+00,\n",
      "          1.2379e+00,  3.8256e-01, -1.0714e+00, -3.1918e-01, -1.2993e+00,\n",
      "         -1.5919e+00,  1.0725e+00,  1.3901e+00,  7.2892e-01,  2.0239e+00,\n",
      "          4.1659e-01, -3.3642e-01,  2.9484e-02,  3.4556e-01, -1.0567e+00,\n",
      "          4.0224e+00, -9.0034e-01,  2.7706e-02,  8.2914e-01,  5.2901e-01,\n",
      "         -2.5557e-01, -1.1096e+00,  1.9794e+00, -2.0617e+00,  9.8352e-01,\n",
      "         -7.0799e-01, -1.9104e-01,  1.3006e+00,  7.9228e-01,  1.4601e+00,\n",
      "          5.9981e-01,  1.4463e+00,  7.9956e-01,  8.0228e-01,  4.5993e-01,\n",
      "          2.7916e+00, -7.7051e-04, -4.5027e-01,  2.8620e-01,  5.5137e-01,\n",
      "          1.2937e+00]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_vector = input_embeddings[0][0]\n",
    "print(input_vector.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "80cd5c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_to_query=input_vector@W_query\n",
    "input_to_key=input_vector@W_key\n",
    "input_to_value=input_vector@W_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b0305992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([72])\n"
     ]
    }
   ],
   "source": [
    "print(input_to_query.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c8add72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_to_querys=input_embeddings@W_query\n",
    "inputs_to_keys=input_embeddings@W_key\n",
    "inputs_to_values=input_embeddings@W_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "896522e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 72])\n",
      "torch.Size([8, 4, 72])\n"
     ]
    }
   ],
   "source": [
    "print(inputs_to_querys.shape)\n",
    "print(inputs_to_keys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2192dfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_key_attention_scores=inputs_to_querys@inputs_to_keys.transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2cd2e8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "\n",
    "d_k=inputs_to_keys.shape[-1]\n",
    "print(d_k)\n",
    "query_key_attention_scores_normalized=torch.softmax(query_key_attention_scores/d_k**0.5,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "36417b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vector=query_key_attention_scores_normalized@inputs_to_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2ea55d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 72])\n"
     ]
    }
   ],
   "source": [
    "print(context_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6678a965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self,d_in,d_out):\n",
    "        super.__init__()\n",
    "        self.W_query=torch.nn.Parameter(torch.rand(d_in,d_out))\n",
    "        self.W_key=torch.nn.Parameter(torch.rand(d_in,d_out))\n",
    "        self.W_value=torch.nn.Parameter(torch.rand(d_in,d_out))\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        queries=x@self.W_query\n",
    "        keys=x@self.W_key\n",
    "        values=x@self.W_values\n",
    "        \n",
    "        attention_scores=queries@keys.T\n",
    "        attention_weights=torch.softmax(attention_scores/keys.shape[-1]**0.5,dim=-1)\n",
    "        context_vectors=attention_weights@values\n",
    "        return context_vectors\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7516443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Just used nn.Linear for better activation. \n",
    "\n",
    "\n",
    "\n",
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self,d_in,d_out,qkv_bias=False):\n",
    "        super.__init__()\n",
    "        self.W_query=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_key=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_value=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "    def forward(self,X):\n",
    "        queries=x@self.W_query\n",
    "        keys=x@self.W_key\n",
    "        values=x@self.W_values\n",
    "        \n",
    "        attention_scores=queries@keys.T\n",
    "        attention_weight=torch.softmax(attention_scores/keys.shape[-1]**0.5,dim=-1)\n",
    "        context_vectors=attention_weight@values\n",
    "        return context_vectors\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1c7be28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "    def __init__(self,d_in,d_out,qkv_bias=False):\n",
    "        super.__init__()\n",
    "        self.W_query=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_key=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_value=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        queries=x@self.W_query\n",
    "        keys=x@self.W_key\n",
    "        values=x@self.W_value\n",
    "        \n",
    "        attention_scores=queries@keys.T\n",
    "        mask=torch.ones(attention_scores.shape[0],attention_scores.shape[1])\n",
    "        mask=torch.triu(mask)\n",
    "        attention_scores[mask==1]=torch.tensor(-float('inf'))\n",
    "        attention_weight=torch.softmax(attention_scores/keys.shape[-1]**0.5,dim=-1)\n",
    "        # drop out here\n",
    "        # The 'train' parameter specifies whether dropout should behave in training mode (drop values) or evaluation mode (no dropout).\n",
    "        # In PyTorch, when train=True, dropout is applied; when train=False, dropout is bypassed.\n",
    "        attention_weight = torch.dropout(attention_weight, p=0.5, train=self.training)\n",
    "        context_vectors=attention_weight@values\n",
    "        return context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "970323e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "    def __init__(self,d_in,d_out,context_length,drop_out,num_heads,qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads=nn.ModuleList([CausalAttention(d_in,d_out,context_length,drop_out,qkv_bias)for _ in range(num_heads)])\n",
    "    def forward(self,x):\n",
    "        return torch.cat([head(x) for head in self.heads],dim=-1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "77f6a10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code in the image and your code are very similar, but there are a few key differences and some mistakes in your implementation.\n",
    "# Here is a version that matches the code in the image, with comments on the differences:\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, drop_out, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "        self.d_out = d_out  # <-- This is missing in your code, but used in .view() later\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.drop_out = nn.Dropout(drop_out)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        # Linear projections\n",
    "        keys = self.W_key(x)      # (b, num_tokens, d_out)\n",
    "        values = self.W_value(x)  # (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x) # (b, num_tokens, d_out)\n",
    "\n",
    "        # Reshape for multi-head: (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose to (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Attention score: (b, num_heads, num_tokens, num_tokens)\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "\n",
    "        # Apply mask (causal)\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        attn_scores = attn_scores.masked_fill(mask_bool, -torch.inf)\n",
    "\n",
    "        # Scale and softmax\n",
    "        attn_weights = torch.softmax(attn_scores / (self.head_dim ** 0.5), dim=-1)\n",
    "        attn_weights = self.drop_out(attn_weights)\n",
    "\n",
    "        # Weighted sum\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)  # (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "        return context_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "76277403",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_configuration = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cde47cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class Dummy_Scratch_gpt_model(nn.Module):\n",
    "    def __init__(self,configuration):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.token_embedding=nn.Embedding(configuration[\"vocab_size\"],configuration[\"emb_dim\"])\n",
    "        self.pos_emb=nn.Embedding(configuration[\"context_length\"],configuration[\"emb_dim\"])\n",
    "        self.drop_emb=nn.Dropout(configuration[\"drop_rate\"])\n",
    "        \n",
    "        self.transformer_blocks=nn.Sequential(\n",
    "            *[Dummy_Transformer_Block(configuration) for _ in range(configuration[\"n_layers\"])]\n",
    "        )\n",
    "    \n",
    "    \n",
    "        self.final_norm=Dummay_Layer_normalization(configuration[\"emb_dim\"])\n",
    "        self.out_head=nn.Linear(configuration[\"emb_dim\"],configuration[\"vocab_size\"],bias=False)\n",
    "        \n",
    "        \n",
    "    def forward(self,in_dx):\n",
    "        batch_size,seq_len=in_dx\n",
    "        tok_embeddings=self.token_embedding(in_dx)\n",
    "        pos_embeddings=self.pos_emb(torch.arange(seq_len,device=in_dx.device))\n",
    "        x=tok_embeddings+pos_embeddings\n",
    "        x=self.drop_emb(x)\n",
    "        x=self.transformer_blocks(x)\n",
    "        x=self.final_norm(x)\n",
    "        logits=self.out_head(x)\n",
    "        return logits\n",
    "        \n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi, device=x.device)) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "class Dummy_FeedForward(nn.Module):\n",
    "    def __init__(self, emb_dim, hidden_dim=None, drop_rate=0.1):\n",
    "        super().__init__()\n",
    "        if hidden_dim is None:\n",
    "            hidden_dim = emb_dim * 4\n",
    "        self.fc1 = nn.Linear(emb_dim, hidden_dim)\n",
    "        self.gelu = GELU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, emb_dim)\n",
    "        self.dropout = nn.Dropout(drop_rate)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class Dummy_SelfAttention(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            drop_out=cfg[\"drop_rate\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.mha(x)\n",
    "\n",
    "class Dummy_Transformer_Block(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.ln1 = Dummay_Layer_normalization(cfg[\"emb_dim\"])\n",
    "        self.attn = Dummy_SelfAttention(cfg)\n",
    "        self.ln2 = Dummay_Layer_normalization(cfg[\"emb_dim\"])\n",
    "        self.ff = Dummy_FeedForward(cfg[\"emb_dim\"], drop_rate=cfg[\"drop_rate\"])\n",
    "    def forward(self, x):\n",
    "        # Attention block with residual\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        # Feedforward block with residual\n",
    "        x = x + self.ff(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class Dummay_Layer_normalization(nn.Module):\n",
    "    def __init__(self, emb_dim, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.eps=eps\n",
    "        self.scale=nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift=nn.Parameter(torch.zeros(emb_dim))\n",
    "    def forward(self, x):\n",
    "        mean=x.mean(-1,keepdim=True)\n",
    "        var=x.var(-1,keepdim=True, unbiased=False)\n",
    "        norm_x=(x-mean)/torch.sqrt(var+self.eps)\n",
    "        return self.scale*norm_x+self.shift\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8d990859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "batch=[]\n",
    "str1 = \"This is the first string.\"\n",
    "str2 = \"This is the second string.\"\n",
    "\n",
    "batch.append(tokenizer.encode(str1))\n",
    "batch.append(tokenizer.encode(str2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "32f6d32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameter count: 163009536\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(22)\n",
    "model = Dummy_Scratch_gpt_model(gpt_configuration)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total parameter count:\", total_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c792c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "adb1f26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 5, 768])\n",
      "Output shape: torch.Size([2, 5, 768])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_input = torch.randn(2, 5, 768)  # (batch, seq_len, emb_dim)\n",
    "transformer_block = Dummy_Transformer_Block(gpt_configuration)\n",
    "output = transformer_block(sample_input)\n",
    "print(\"Input shape:\", sample_input.shape)\n",
    "print(\"Output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b958cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "32927ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "gelu = GELU()\n",
    "\n",
    "x = torch.linspace(-5, 5, 1000)\n",
    "y = gelu(x)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x.numpy(), y.detach().numpy(), label=\"GELU\")\n",
    "plt.title(\"GELU Activation Function\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"GELU(x)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362b6834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
